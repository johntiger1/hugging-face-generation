{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Copy of t5-trivia",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johntiger1/hugging-face-generation/blob/master/Copy_of_t5_trivia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0egdFGNiWeoq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndixOWJhWjCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YONnGjpAYUdU"
      },
      "source": [
        "\n",
        "<a href=\"https://colab.research.google.com/github/google-research/text-to-text-transfer-transformer/blob/master/notebooks/t5-trivia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zrtR2urJV3ST"
      },
      "source": [
        "##### Copyright 2020 The T5 Authors\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DWdCSqJ6WHBh",
        "colab": {}
      },
      "source": [
        "# Copyright 2019 The T5 Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zSeyoqE7WMwu"
      },
      "source": [
        "# Fine-Tuning the Text-To-Text Transfer Transformer (T5) for Closed-Book Question Answering\n",
        "## _Or: What does T5 know?_\n",
        "\n",
        "*The following tutorial guides you through the process of fine-tuning a pre-trained T5 model, evaluating its accuracy, and using it for prediction,\n",
        "all on a free Google Cloud TPU <a href=\"https://colab.research.google.com/github/google-research/text-to-text-transfer-transformer/blob/master/notebooks/t5-trivia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>.*\n",
        "\n",
        "### Background\n",
        "\n",
        "T5 was introduced in the paper [_Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer_](https://arxiv.org/abs/1910.10683). In that paper, we provided a comprehensive picture of how we pre-trained a standard text-to-text Transformer model on a large text corpus, achieving state-of-the-art results on many NLP tasks after fine-tuning.\n",
        "\n",
        "We pre-trained T5 on a mixture of supervised and unsupervised tasks with the majoriy of data coming from an unlabeled dataset we developed called [C4](https://www.tensorflow.org/datasets/catalog/c4). C4 is based on a massive scrape of the web produced by [Common Crawl](https://commoncrawl.org). Loosely speaking, pre-training on C4 ideally gives T5 an understanding of natural language in addition to general world knowledge.\n",
        "\n",
        "### How can we assess what T5 knows?\n",
        "\n",
        "As the name implies, T5 is a text-to-text model, which enables us to train it on arbitrary tasks involving a textual input and output. As we showed in our paper, a huge variety of NLP tasks can be cast in this format, including translation, summarization, and even classification and regression tasks.\n",
        "\n",
        "One way to use this text-to-text framework is on reading comprehension problems, where the model is fed some context along with a question and is trained to predict the question's answer. For example, we might feed the model the text from the Wikipedia article about [Hurrican Connie](https://en.wikipedia.org/wiki/Hurricane_Connie) along with the question \"On what date did Hurricane Connie occur?\" and train the model to predict the answer \"August 3rd, 1955\".\n",
        "A related task is open-domain question answering (QA) where the model is not provided with this oracle context. Typically, open-domain QA systems include a mechanism to look up information in an external knowledge source. This setting is similar to an \"open-book\" exam.\n",
        "\n",
        "In this notebook, we'll be training T5 on a variant of this task which we call **closed-book question answering**. In closed-book QA, we feed the model a question *without any context or access to external knowledge* and train it to predict the answer. Since the model doesn't receive any context, the primary way it can learn to answer these questions is based on the \"knowledge\" it obtained during pre-training. We don't expect T5 to contain super specific information, so we will be focusing on two question-answering datasets which largely include trivia questions (i.e. facts about well-known subjects). [Similar](https://arxiv.org/abs/1909.01066) [investigations](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) have recently been done to test the knowledge stored by BERT and GPT-2.\n",
        "\n",
        "T5 was not pre-trained on closed-book QA, so in this notebook we'll first create two new tasks and then use the [`t5`](https://github.com/google-research/text-to-text-transfer-transformer) library to fine-tune, evaluate, and obtain predictions from T5. In the end, T5's performance on closed-book QA can give us a sense of what kind (and how much) information T5 managed to learn during pre-training.\n",
        "\n",
        "## State-of-the-art Results\n",
        "We published a [more in-depth investigation](https://arxiv.org/abs/2002.08910) of closed-book QA with T5 where we achieved SOTA on open-domain variants of WebQuestions and TriviaQA in addition to surpisingly strong results on Natural Questions. The code in this notebook is a simplified version of those experiments but still produces good results.\n",
        "\n",
        "For code to reproduce our best results, please see the [t5_closed_book_qa](https://github.com/google-research/google-research/tree/master/t5_closed_book_qa) repo.\n",
        "\n",
        "\n",
        "### Caveats\n",
        "\n",
        "* While we provide instructions for running on a [Cloud TPU](https://cloud.google.com/tpu/) via Colab for free, a [Google Cloud Storage (GCS)](http://console.cloud.google.com/storage) bucket is required for storing model parameters and data. The [GCS free tier](https://cloud.google.com/free/) provides 5 GB of storage, which should be enough to train the `large` model and smaller but not the `3B` or `11B` parameter models. You can use part of your initial $300 credit to get more space.\n",
        "* The Cloud TPU provided by Colab (a `v2-8`) does not have enough memory to fine-tune the `11B` parameter model. For this model, you will need to fine-tune inside of a GCP instance (see [README](https://github.com/google-research/text-to-text-transfer-transformer/)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yAb_APDrefs6"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eDeE_yVuHMYg"
      },
      "source": [
        "<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Train on TPU</h3>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   1. Create a Cloud Storage bucket for your data and model checkpoints at http://console.cloud.google.com/storage, and fill in the `BASE_DIR` parameter in the following form. There is a [free tier](https://cloud.google.com/free/) if you do not yet have an account.\n",
        " \n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Run the following cell and follow instructions to:\n",
        "    *  Set up a Colab TPU running environment\n",
        "    *   Verify that you are connected to a TPU device\n",
        "    *   Upload your credentials to TPU to access your GCS bucket\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPRSKWzJsGKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6cc2a7aa-379a-4fef-80b1-f8b07cb84976"
      },
      "source": [
        "print(\"Installing dependencies...\")\n",
        "# %tensorflow_version 2.1\n",
        "!pip install t5==0.6.2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing dependencies...\n",
            "Requirement already satisfied: t5==0.6.2 in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (1.4.1)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (1.4.13)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (0.1.91)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (0.22.2.post1)\n",
            "Requirement already satisfied: transformers>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (3.0.2)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (0.0.4)\n",
            "Requirement already satisfied: mesh-tensorflow[transformer]>=0.1.13 in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (0.1.16)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (0.9.0)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (3.2.1.dev202008140105)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (1.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (1.18.5)\n",
            "Requirement already satisfied: six>=1.14 in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (1.6.0+cu101)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (2.3.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (0.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (3.2.5)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (from t5==0.6.2) (2.8.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu->t5==0.6.2) (2.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->t5==0.6.2) (0.16.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.6.2) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.6.2) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.6.2) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.6.2) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.6.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.6.2) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.6.2) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.6.2) (0.8.1rc1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.6.2) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets; extra == \"transformer\" in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.6.2) (2.1.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.6.2) (0.22.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.6.2) (0.3.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.6.2) (19.3.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.6.2) (3.0.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.6.2) (1.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.6.2) (1.12.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.6.2) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.6.2) (3.12.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->t5==0.6.2) (0.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->t5==0.6.2) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->t5==0.6.2) (2018.9)\n",
            "Requirement already satisfied: tensorflow<2.4,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->t5==0.6.2) (2.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.7.0->t5==0.6.2) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.6.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.6.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.6.2) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.6.2) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.6.2) (7.1.2)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tfds-nightly->t5==0.6.2) (1.52.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tfds-nightly->t5==0.6.2) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tfds-nightly->t5==0.6.2) (49.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (1.31.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (1.6.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (0.34.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (2.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (1.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.6.2) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiDr-3oBuLoh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7bed4a95-cae7-4813-c568-17429b4e4ed7"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "xYh-IaN4C7Z1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "a023b673-79b4-49c3-de0b-3f90ed57106f"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "BASE_DIR = \"gs://t5-open-qa-bucket\" #@param { type: \"string\" }\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "\n",
        "if ON_CLOUD:\n",
        "  print(\"Setting up GCS access...\")\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  print(\"we are auth\")\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n",
            "Setting up GCS access...\n",
            "Running on TPU: grpc://10.67.195.82:8470\n",
            "we are auth\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvolr7qwrpcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf0CiFzfrstP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76e90f99-80b8-4646-afc7-14bb7e04dd32"
      },
      "source": [
        "tensorflow.__version__"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dMoJ-G9mqDqa"
      },
      "source": [
        "# Creating new Tasks and Mixture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zwoLPQhE6bef"
      },
      "source": [
        "Two core components of the T5 library are `Task` and `Mixture` objects.\n",
        "\n",
        "A `Task` is a dataset along with preprocessing functions and evaluation metrics. A `Mixture` is a collection of `Task` objects along with a mixing rate or a function defining how to compute a mixing rate based on the properties of the constituent `Tasks`.\n",
        "\n",
        "For this example, we will fine-tune the model to do closed-book question answering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "152zECujzPMk"
      },
      "source": [
        "### Natural Questions\n",
        "\n",
        "[Natural Questions (NQ)](https://ai.google.com/research/NaturalQuestions) is a challenging corpus for open-domain QA. Each example includes a question along with an entire Wikipedia article that may or may not contain its answer. The goal is to produce the correct answer given this context. In our case, we will be ignoring the provided context in hopes that the model will learn to find the answers from the world knowledge it has acquired during pre-training.\n",
        "\n",
        "Since the raw data splits are stored as JSONL files, we will first need to convert them to TSV format to make them parseable in TensorFlow. We will also take the opportunity to drop information we will not be using, remove questions with multiple answers, and to do a bit of cleaning of the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OjEonhK3zNRu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd3286f9-e8c1-4dcf-ac34-8ff158d44379"
      },
      "source": [
        "import gzip\n",
        "import json\n",
        "\n",
        "# Public directory of Natural Questions data on GCS.\n",
        "NQ_JSONL_DIR = \"gs://natural_questions/v1.0-simplified/\"\n",
        "NQ_SPLIT_FNAMES = {\n",
        "    \"train\": \"simplified-nq-train.jsonl.gz\",\n",
        "    \"validation\": \"nq-dev-all.jsonl.gz\"\n",
        "}\n",
        "nq_counts_path = os.path.join(DATA_DIR, \"nq-counts.json\")\n",
        "nq_tsv_path = {\n",
        "    \"train\": os.path.join(DATA_DIR, \"nq-train.tsv\"),\n",
        "    \"validation\": os.path.join(DATA_DIR, \"nq-validation.tsv\")\n",
        "}\n",
        "\n",
        "covid_qa_tsv_path = {\n",
        "    \"train\": os.path.join(DATA_DIR, \"cleaned-covid-train.tsv\"),\n",
        "    \"validation\": os.path.join(DATA_DIR, \"cleaned-covid-valid.tsv\")\n",
        "\n",
        "}\n",
        "\n",
        "import pandas as pd\n",
        "def csv_to_tsv(in_fname, out_fname):\n",
        "  my_df = pd.load_csv(in_fname)\n",
        "\n",
        "  \n",
        "\n",
        "'''\n",
        "We need to redo it:\n",
        "formulate the COVID-19 in this format\n",
        "'''\n",
        "from tqdm.auto import tqdm\n",
        "def nq_jsonl_to_tsv(in_fname, out_fname):\n",
        "\n",
        "  def extract_answer(tokens, span):\n",
        "    \"\"\"Reconstruct answer from token span and remove extra spaces.\"\"\"\n",
        "    start, end = span[\"start_token\"], span[\"end_token\"]  \n",
        "    ans = \" \".join(tokens[start:end])\n",
        "    # Remove incorrect spacing around punctuation.\n",
        "    ans = ans.replace(\" ,\", \",\").replace(\" .\", \".\").replace(\" %\", \"%\")\n",
        "    ans = ans.replace(\" - \", \"-\").replace(\" : \", \":\").replace(\" / \", \"/\")\n",
        "    ans = ans.replace(\"( \", \"(\").replace(\" )\", \")\")\n",
        "    ans = ans.replace(\"`` \", \"\\\"\").replace(\" ''\", \"\\\"\")\n",
        "    ans = ans.replace(\" 's\", \"'s\").replace(\"s ' \", \"s' \")\n",
        "    return ans\n",
        "\n",
        "  count = 0\n",
        "  with tf.io.gfile.GFile(in_fname, \"rb\") as infile,\\\n",
        "       tf.io.gfile.GFile(out_fname, \"w\") as outfile:\n",
        "    for line in tqdm(gzip.open(infile)):\n",
        "      ex = json.loads(line)\n",
        "      # Remove any examples with more than one answer.\n",
        "      if len(ex['annotations'][0]['short_answers']) != 1:\n",
        "        continue\n",
        "      # Questions in NQ do not include a question mark.\n",
        "      question = ex[\"question_text\"] + \"?\"\n",
        "      answer_span = ex['annotations'][0]['short_answers'][0]\n",
        "      # Handle the two document formats in NQ (tokens or text).\n",
        "      if \"document_tokens\" in ex:\n",
        "        tokens = [t[\"token\"] for t in ex[\"document_tokens\"]]\n",
        "      elif \"document_text\" in ex:\n",
        "        tokens = ex[\"document_text\"].split(\" \")\n",
        "      answer = extract_answer(tokens, answer_span)\n",
        "      # Write this line as <question>\\t<answer>\n",
        "      outfile.write(\"%s\\t%s\\n\" % (question, answer)) # we just need Q TAB A pairs\n",
        "      count += 1\n",
        "      tf.logging.log_every_n(\n",
        "          tf.logging.INFO,\n",
        "          \"Wrote %d examples to %s.\" % (count, out_fname),\n",
        "          1000)\n",
        "      # if count > 100 and count % 10000 == 0:\n",
        "      #   print(\"nice, finsihed 10k examples\")\n",
        "      #   break\n",
        "    return count\n",
        "\n",
        "if tf.io.gfile.exists(nq_counts_path):\n",
        "  # Used cached data and counts.\n",
        "  tf.logging.info(\"Loading NQ from cache.\")\n",
        "  num_nq_examples = json.load(tf.io.gfile.GFile(nq_counts_path))\n",
        "else:\n",
        "  # Create TSVs and get counts.\n",
        "  tf.logging.info(\"Generating NQ TSVs.\")\n",
        "  num_nq_examples = {}\n",
        "  for split, fname in NQ_SPLIT_FNAMES.items():\n",
        "    num_nq_examples[split] = nq_jsonl_to_tsv(\n",
        "        os.path.join(NQ_JSONL_DIR, fname), nq_tsv_path[split])\n",
        "  json.dump(num_nq_examples, tf.io.gfile.GFile(nq_counts_path, \"w\"))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loading NQ from cache.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTgmhCNRM1aE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9b5734b-0022-483e-fe36-416828252470"
      },
      "source": [
        "num_nq_examples"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 96499, 'validation': 2338}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC40Vr7-bBWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "fdf677d3-4ca8-4766-b408-ebcab8390ff0"
      },
      "source": [
        "pip install gcsfs"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.8.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.17.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (49.2.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2020.6.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth>=1.2->gcsfs) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOcdoXNhc2O4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b405b6c7-439e-45b2-8182-0f26bb8814bf"
      },
      "source": [
        "DATA_DIR"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gs://t5-open-qa-bucket/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3phaYYqdGiGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBrpD28cGkUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_df = pd.read_csv(os.path.join(DATA_DIR,\"cleaned_QA_COVID_19_General.csv\"))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phswz87KJXW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "66e3fb42-96b1-4194-8c00-93619e885553"
      },
      "source": [
        "my_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>text</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is a coronavirus?</td>\n",
              "      <td>Coronaviruses are a large family of viruses wh...</td>\n",
              "      <td>a large family of viruses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is COVID-19?</td>\n",
              "      <td>COVID-19 is the infectious disease caused by t...</td>\n",
              "      <td>infectious disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what are the symptoms of COVID-19?</td>\n",
              "      <td>The most common symptoms of COVID-19 are fever...</td>\n",
              "      <td>fever, tiredness, and dry cough</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How does COVID-19 spread?</td>\n",
              "      <td>People can catch COVID-19 from others who have...</td>\n",
              "      <td>spread from person to person through small dro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How likely am I to catch COVID-19?</td>\n",
              "      <td>The risk depends on where you  are - and more ...</td>\n",
              "      <td>in most locations the risk of catching COVID-1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>\\nHow does the virus spread?</td>\n",
              "      <td>Officials are still learning about how COVID-1...</td>\n",
              "      <td>From touching our mouths, noses or eyes after ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>How does the virus spread?</td>\n",
              "      <td>Officials are still learning about how COVID-1...</td>\n",
              "      <td>From close contact with people who have it.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>How does the virus spread?</td>\n",
              "      <td>Officials are still learning about how COVID-1...</td>\n",
              "      <td>From respiratory droplets that become airborne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>\\nWill warm weather stop the outbreak of COVID...</td>\n",
              "      <td>Researchers are still learning about how easil...</td>\n",
              "      <td>it’s unclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>\\nWhere can I find more information about COVI...</td>\n",
              "      <td>The Centers for Disease Control and Prevention...</td>\n",
              "      <td>The Centers for Disease Control and Prevention...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              question  ...                                             answer\n",
              "0                               What is a coronavirus?  ...                         a large family of viruses \n",
              "1                                    what is COVID-19?  ...                                 infectious disease\n",
              "2                   what are the symptoms of COVID-19?  ...                    fever, tiredness, and dry cough\n",
              "3                            How does COVID-19 spread?  ...  spread from person to person through small dro...\n",
              "4                   How likely am I to catch COVID-19?  ...  in most locations the risk of catching COVID-1...\n",
              "..                                                 ...  ...                                                ...\n",
              "192                       \\nHow does the virus spread?  ...  From touching our mouths, noses or eyes after ...\n",
              "193                         How does the virus spread?  ...      From close contact with people who have it.\\n\n",
              "194                         How does the virus spread?  ...  From respiratory droplets that become airborne...\n",
              "195  \\nWill warm weather stop the outbreak of COVID...  ...                                      it’s unclear \n",
              "196  \\nWhere can I find more information about COVI...  ...  The Centers for Disease Control and Prevention...\n",
              "\n",
              "[197 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL9GSbDtNgH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "98116f69-c9a3-4722-bd47-ee4bcf02ebc8"
      },
      "source": [
        "my_df.dtypes"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question    object\n",
              "text        object\n",
              "answer      object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DasarXqcJJB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_df = my_df.astype(pd.StringDtype())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwnmaM6eJ4Ih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a9debeda-67a7-4818-fd3d-4d1232f888d6"
      },
      "source": [
        "my_df.dtypes"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question    string\n",
              "text        string\n",
              "answer      string\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbxXOssNJ-D8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "relevant_df = my_df[[\"question\", \"answer\"]].dropna()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDWakCl9VsDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d348564-13fa-4c88-e412-3f084d66c9e9"
      },
      "source": [
        "len(relevant_df)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPOTLt8eKfzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# relevant_df.iloc[432,1]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N78lx9DRJgqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# incredibly, some of them are floats!!\n",
        "relevant_df[\"question\"] = relevant_df[\"question\"].map(lambda x: x.replace(\"\\n\", \" \"))\n",
        "relevant_df[\"answer\"] = relevant_df[\"answer\"].map(lambda x: x.replace(\"\\n\", \" \"))\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w3gqty0GMDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9104fcc1-1c0b-449c-e633-015a37674d51"
      },
      "source": [
        "my_df.dtypes"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question    string\n",
              "text        string\n",
              "answer      string\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0cdXpWcDfLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "6d98981e-6591-49d2-8f37-8141af518457"
      },
      "source": [
        "relevant_df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is a coronavirus?</td>\n",
              "      <td>a large family of viruses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is COVID-19?</td>\n",
              "      <td>infectious disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what are the symptoms of COVID-19?</td>\n",
              "      <td>fever, tiredness, and dry cough</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How does COVID-19 spread?</td>\n",
              "      <td>spread from person to person through small dro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How likely am I to catch COVID-19?</td>\n",
              "      <td>in most locations the risk of catching COVID-1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>How does the virus spread?</td>\n",
              "      <td>From touching our mouths, noses or eyes after ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>How does the virus spread?</td>\n",
              "      <td>From close contact with people who have it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>How does the virus spread?</td>\n",
              "      <td>From respiratory droplets that become airborne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>Will warm weather stop the outbreak of COVID-19?</td>\n",
              "      <td>it’s unclear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>Where can I find more information about COVID...</td>\n",
              "      <td>The Centers for Disease Control and Prevention...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              question                                             answer\n",
              "0                               What is a coronavirus?                         a large family of viruses \n",
              "1                                    what is COVID-19?                                 infectious disease\n",
              "2                   what are the symptoms of COVID-19?                    fever, tiredness, and dry cough\n",
              "3                            How does COVID-19 spread?  spread from person to person through small dro...\n",
              "4                   How likely am I to catch COVID-19?  in most locations the risk of catching COVID-1...\n",
              "..                                                 ...                                                ...\n",
              "192                         How does the virus spread?  From touching our mouths, noses or eyes after ...\n",
              "193                         How does the virus spread?       From close contact with people who have it. \n",
              "194                         How does the virus spread?  From respiratory droplets that become airborne...\n",
              "195   Will warm weather stop the outbreak of COVID-19?                                      it’s unclear \n",
              "196   Where can I find more information about COVID...  The Centers for Disease Control and Prevention...\n",
              "\n",
              "[178 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D42I3Nbhw81F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b3b86bd-43ff-4d21-97a6-b79de3591b30"
      },
      "source": [
        "len(relevant_df[\"question\"].unique())\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DBd_Q6cxnQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "539fafa1-a3a6-4bd3-860e-ce5401515889"
      },
      "source": [
        "relevant_df.groupby(\"question\").count().sort_values(by=\"answer\", ascending=False)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>How can I protect myself from getting COVID-19?</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How can I ask for help?</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How does the virus spread?</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are there any tests that I can purchase to test myself at home for COVID-19?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What happens if a pregnant worker is exposed to COVID-19 while on reassignment in a healthcare setting, including a dedicated COVID-19 clinic?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How long will the results take?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How must the employer verify the state of health of the workers arriving on the work site?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How should I clean my environment?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to put on, use,take off and dispose of a mask?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What are the measures to be implemented on construction sites to reduce contamination linked to COVID-19?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    answer\n",
              "question                                                  \n",
              "How can I protect myself from getting COVID-19?          7\n",
              "How can I ask for help?                                  2\n",
              "How does the virus spread?                               2\n",
              " Are there any tests that I can purchase to tes...       1\n",
              "What happens if a pregnant worker is exposed to...       1\n",
              "...                                                    ...\n",
              "How long will the results take?                          1\n",
              "How must the employer verify the state of healt...       1\n",
              "How should I clean my environment?                       1\n",
              "How to put on, use,take off and dispose of a mask?       1\n",
              " What are the measures to be implemented on con...       1\n",
              "\n",
              "[170 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG3CFf6bx8lL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd2a4ffc-81bd-4294-df1f-a609865d4b1c"
      },
      "source": [
        "\n",
        "len(relevant_df.groupby(\"question\").count().sort_values(by=\"answer\", ascending=False))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBirqPtX9uTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ed1fa7e-a3da-4f51-aece-6067572d9c58"
      },
      "source": [
        "type(relevant_df.groupby(\"question\").count().sort_values(by=\"answer\", ascending=False))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zaXg-_-96hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c39820d5-76f6-4709-967e-d26ae5d1548d"
      },
      "source": [
        "isinstance(relevant_df.groupby(\"question\").count().sort_values(by=\"answer\", ascending=False), pd.DataFrame)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHbDMAIu-aM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "8ddeb9da-e4fd-4442-d839-54f0bded9344"
      },
      "source": [
        "relevant_df.groupby(\"question\").count().sort_values(by=\"answer\", ascending=False).index # the index is now over questions "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['How can I protect myself from getting COVID-19?',\n",
              "       'How can I ask for help?', 'How does the virus spread?',\n",
              "       ' Are there any tests that I can purchase to test myself at home for COVID-19?',\n",
              "       'What happens if a pregnant worker is exposed to COVID-19 while on reassignment in a healthcare setting, including a dedicated COVID-19 clinic?',\n",
              "       'What can I do to help those who are vulnerable in Oxford?',\n",
              "       'What can National Veterinary Services do with regards to companion animals?',\n",
              "       'What do I do if my workplace first aid card expires?',\n",
              "       'What does it really mean to self-isolate or self-quarantine? What should or shouldn't I do?',\n",
              "       'What does the CNESST suggest for my employer, who has arranged a medical assessment?',\n",
              "       ...\n",
              "       'How does COVID-19 spread?',\n",
              "       'How does the CNESST intervene in the case of a priority or non-priority business?',\n",
              "       'How does the testing work?', 'How likely am I to catch COVID-19?',\n",
              "       'How long is the incubation period for COVID-19?',\n",
              "       'How long will the results take?',\n",
              "       'How must the employer verify the state of health of the workers arriving on the work site?',\n",
              "       'How should I clean my environment?',\n",
              "       'How to put on, use,take off and dispose of a mask?',\n",
              "       ' What are the measures to be implemented on construction sites to reduce contamination linked to COVID-19?'],\n",
              "      dtype='object', name='question', length=170)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeRDxIhT-pwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped_questions_df = relevant_df.groupby(\"question\").count().sort_values(by=\"answer\", ascending=False)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK52mYon-1jQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVE4eUY7-BQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (relevant_df.groupby(\"question\").count().sort_values(by=\"answer\", ascending=False)) == pd.DataFrame"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzjpjEyux50n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure that repeated questions are dumped in the same split\n",
        "# to do this, we simply need to split up everything , and assign labels too. Give the indexes to the appropriate people.\n",
        "# let's handroll it and see what happens!! \n",
        "import numpy as np"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E52ttlVl9m_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c82035b5-e6cb-4982-9278-e683fff04f93"
      },
      "source": [
        "np.random.binomial(1, 0.05, size=(len(grouped_questions_df))) # want K binomial samples"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD1bQHqoKO5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = np.random.binomial(1, 0.05, size=(len(grouped_questions_df))) "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Fjtl8OKkgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples_df = pd.DataFrame(samples, columns=[\"test\"])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0csQB6_nLR8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c8cfb497-2972-45d4-be3d-8e85d751dd83"
      },
      "source": [
        "samples_df"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     test\n",
              "0       0\n",
              "1       0\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "..    ...\n",
              "165     0\n",
              "166     0\n",
              "167     0\n",
              "168     0\n",
              "169     0\n",
              "\n",
              "[170 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV3rvwMoLQFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "6de4fa3a-7cd2-4762-8b51-9861bf6e516d"
      },
      "source": [
        "grouped_questions_df"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>How can I protect myself from getting COVID-19?</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How can I ask for help?</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How does the virus spread?</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are there any tests that I can purchase to test myself at home for COVID-19?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What happens if a pregnant worker is exposed to COVID-19 while on reassignment in a healthcare setting, including a dedicated COVID-19 clinic?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How long will the results take?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How must the employer verify the state of health of the workers arriving on the work site?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How should I clean my environment?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to put on, use,take off and dispose of a mask?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What are the measures to be implemented on construction sites to reduce contamination linked to COVID-19?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    answer\n",
              "question                                                  \n",
              "How can I protect myself from getting COVID-19?          7\n",
              "How can I ask for help?                                  2\n",
              "How does the virus spread?                               2\n",
              " Are there any tests that I can purchase to tes...       1\n",
              "What happens if a pregnant worker is exposed to...       1\n",
              "...                                                    ...\n",
              "How long will the results take?                          1\n",
              "How must the employer verify the state of healt...       1\n",
              "How should I clean my environment?                       1\n",
              "How to put on, use,take off and dispose of a mask?       1\n",
              " What are the measures to be implemented on con...       1\n",
              "\n",
              "[170 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t278LYB5L2pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_questions_df = grouped_questions_df.reset_index()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EXGDl1GL-E_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "90a47e63-07d4-4729-ffc0-b366d6386b79"
      },
      "source": [
        "unique_questions_df"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How can I protect myself from getting COVID-19?</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can I ask for help?</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the virus spread?</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Are there any tests that I can purchase to te...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What happens if a pregnant worker is exposed t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>How long will the results take?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>How must the employer verify the state of heal...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>How should I clean my environment?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>How to put on, use,take off and dispose of a m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>What are the measures to be implemented on co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              question  answer\n",
              "0      How can I protect myself from getting COVID-19?       7\n",
              "1                              How can I ask for help?       2\n",
              "2                           How does the virus spread?       2\n",
              "3     Are there any tests that I can purchase to te...       1\n",
              "4    What happens if a pregnant worker is exposed t...       1\n",
              "..                                                 ...     ...\n",
              "165                    How long will the results take?       1\n",
              "166  How must the employer verify the state of heal...       1\n",
              "167                 How should I clean my environment?       1\n",
              "168  How to put on, use,take off and dispose of a m...       1\n",
              "169   What are the measures to be implemented on co...       1\n",
              "\n",
              "[170 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObUDgHrDKSX8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d337d31e-bf56-4ec1-a5fb-0e17746c0b8c"
      },
      "source": [
        "# now, concat things, and then select the df based on them. Will require one last final join too\n",
        "pd.concat((unique_questions_df,samples_df), axis=1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How can I protect myself from getting COVID-19?</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can I ask for help?</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the virus spread?</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Are there any tests that I can purchase to te...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What happens if a pregnant worker is exposed t...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>How long will the results take?</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>How must the employer verify the state of heal...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>How should I clean my environment?</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>How to put on, use,take off and dispose of a m...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>What are the measures to be implemented on co...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              question  answer  test\n",
              "0      How can I protect myself from getting COVID-19?       7     0\n",
              "1                              How can I ask for help?       2     0\n",
              "2                           How does the virus spread?       2     1\n",
              "3     Are there any tests that I can purchase to te...       1     0\n",
              "4    What happens if a pregnant worker is exposed t...       1     0\n",
              "..                                                 ...     ...   ...\n",
              "165                    How long will the results take?       1     0\n",
              "166  How must the employer verify the state of heal...       1     0\n",
              "167                 How should I clean my environment?       1     0\n",
              "168  How to put on, use,take off and dispose of a m...       1     0\n",
              "169   What are the measures to be implemented on co...       1     0\n",
              "\n",
              "[170 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w84u_nOAMNOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assignments_df = pd.concat((unique_questions_df,samples_df), axis=1).drop([\"answer\"], axis=1)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgNR-EIgND1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdWJJMNtNBMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assignments_df.drop([\"answer\"], axis=1)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tPOUrSXMUWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "expanded_assignments_df = relevant_df.merge(assignments_df, left_on=[\"question\"], right_on=[\"question\"], how=\"inner\") "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Zh6B-ZW4Mk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0d613938-7165-42bc-80fa-5914140fbe87"
      },
      "source": [
        "expanded_assignments_df[\"test\"].describe()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    178.000000\n",
              "mean       0.050562\n",
              "std        0.219719\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        0.000000\n",
              "max        1.000000\n",
              "Name: test, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfzBUh0TXADg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_nMOG3YNAWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "17d41424-d49b-42cb-fdf2-8e1f3e8df7cc"
      },
      "source": [
        "expanded_assignments_df.groupby([\"question\", \"test\"]).count().sort_values(by=\"answer\", ascending=False)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question</th>\n",
              "      <th>test</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>How can I protect myself from getting COVID-19?</th>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How can I ask for help?</th>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How does the virus spread?</th>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are there any tests that I can purchase to test myself at home for COVID-19?</th>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What happens if a pregnant worker is exposed to COVID-19 while on reassignment in a healthcare setting, including a dedicated COVID-19 clinic?</th>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How long will the results take?</th>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How must the employer verify the state of health of the workers arriving on the work site?</th>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How should I clean my environment?</th>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to put on, use,take off and dispose of a mask?</th>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What are the measures to be implemented on construction sites to reduce contamination linked to COVID-19?</th>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                         answer\n",
              "question                                           test        \n",
              "How can I protect myself from getting COVID-19?    0          7\n",
              "How can I ask for help?                            0          2\n",
              "How does the virus spread?                         1          2\n",
              " Are there any tests that I can purchase to tes... 0          1\n",
              "What happens if a pregnant worker is exposed to... 0          1\n",
              "...                                                         ...\n",
              "How long will the results take?                    0          1\n",
              "How must the employer verify the state of healt... 0          1\n",
              "How should I clean my environment?                 0          1\n",
              "How to put on, use,take off and dispose of a mask? 0          1\n",
              " What are the measures to be implemented on con... 0          1\n",
              "\n",
              "[170 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-J1CLDgOPi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "9faf9cc4-c3cc-481d-95b4-c2764318c3a1"
      },
      "source": [
        "expanded_assignments_df.groupby([\"question\"]).agg(\"sum\").sort_values(by=\"test\",ascending=False)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>How does the virus spread?</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is the OIE doing?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are screening tests effective if you don’t have symptoms?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What can I do if I do not receive a record of employment or termination of employment?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What can National Veterinary Services do with regards to companion animals?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How long will the results take?</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How must the employer verify the state of health of the workers arriving on the work site?</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How should I clean my environment?</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to put on, use,take off and dispose of a mask?</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What are the measures to be implemented on construction sites to reduce contamination linked to COVID-19?</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    test\n",
              "question                                                \n",
              "How does the virus spread?                             2\n",
              "What is the OIE doing?                                 1\n",
              "Are screening tests effective if you don’t have...     1\n",
              "What can I do if I do not receive a record of e...     1\n",
              "What can National Veterinary Services do with r...     1\n",
              "...                                                  ...\n",
              "How long will the results take?                        0\n",
              "How must the employer verify the state of healt...     0\n",
              "How should I clean my environment?                     0\n",
              "How to put on, use,take off and dispose of a mask?     0\n",
              " What are the measures to be implemented on con...     0\n",
              "\n",
              "[170 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COxsD0TgM2OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_train_df = expanded_assignments_df[expanded_assignments_df[\"test\"]==0].drop(\"test\",axis=1)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tidznrg0XIpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_test_df = expanded_assignments_df[expanded_assignments_df[\"test\"]==1].drop(\"test\",axis=1)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CqMSNaXXPVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "8d07d799-f37a-4579-ad14-1bea2275e023"
      },
      "source": [
        "unique_test_df"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>How do we know if a vaccine is likely to work?</td>\n",
              "      <td>vaccines go into human trials after tests for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Are screening tests effective if you don’t hav...</td>\n",
              "      <td>it cannot be confirmed that tests done on peo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>Do I have the right to sick leave?</td>\n",
              "      <td>Yes. You have the right to be off work, withou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>What can I do if I do not receive a record of ...</td>\n",
              "      <td>your employer must pay you an indemnity equal ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>What can National Veterinary Services do with ...</td>\n",
              "      <td>Public Health and Veterinary Services should w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>What is the OIE doing?</td>\n",
              "      <td>The OIE is closely liaising with its network ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>What types of medications and health supplies ...</td>\n",
              "      <td>Medical and health supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>How does the virus spread?</td>\n",
              "      <td>From close contact with people who have it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>How does the virus spread?</td>\n",
              "      <td>From respiratory droplets that become airborne...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              question                                             answer\n",
              "24      How do we know if a vaccine is likely to work?  vaccines go into human trials after tests for ...\n",
              "54   Are screening tests effective if you don’t hav...   it cannot be confirmed that tests done on peo...\n",
              "93                  Do I have the right to sick leave?  Yes. You have the right to be off work, withou...\n",
              "100  What can I do if I do not receive a record of ...  your employer must pay you an indemnity equal ...\n",
              "134  What can National Veterinary Services do with ...  Public Health and Veterinary Services should w...\n",
              "137                             What is the OIE doing?   The OIE is closely liaising with its network ...\n",
              "147  What types of medications and health supplies ...                       Medical and health supplies \n",
              "174                         How does the virus spread?       From close contact with people who have it. \n",
              "175                         How does the virus spread?  From respiratory droplets that become airborne..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OBU8qpiXVC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "c72de726-c33b-4fd3-9f21-9c29dddc45dd"
      },
      "source": [
        "unique_train_df.groupby(\"question\").count().sort_values(by=\"answer\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Are there any tests that I can purchase to test myself at home for COVID-19?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What are the Veterinary Authority’s international responsibilities in this event?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What are the new tests coming?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What are the preventive measures to be implemented during work on a contaminated site?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What are the steps for a pregnant worker to apply for reassignment due to the coronavirus?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How must the employer verify the state of health of the workers arriving on the work site?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How did the first human SARS-CoV-2 infections occcur?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What are the measures to be implemented on construction sites to reduce contamination linked to COVID-19?</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How can I ask for help?</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How can I protect myself from getting COVID-19?</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    answer\n",
              "question                                                  \n",
              " Are there any tests that I can purchase to tes...       1\n",
              "What are the Veterinary Authority’s internation...       1\n",
              "What are the new tests coming?                           1\n",
              "What are the preventive measures to be implemen...       1\n",
              "What are the steps for a pregnant worker to app...       1\n",
              "...                                                    ...\n",
              "How must the employer verify the state of healt...       1\n",
              "How did the first human SARS-CoV-2 infections o...       1\n",
              " What are the measures to be implemented on con...       1\n",
              "How can I ask for help?                                  2\n",
              "How can I protect myself from getting COVID-19?          7\n",
              "\n",
              "[162 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRe1muVSXLgQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8498ce5a-02f4-4ce8-efef-602c3bbc7976"
      },
      "source": [
        "len(unique_test_df)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXTOoXUyd_xJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_train_df.to_csv(os.path.join(DATA_DIR,\"cleaned-covid-train.tsv\"),sep=\"\\t\",index=False, header=False)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNH3vn5rd6L4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_test_df.to_csv(os.path.join(DATA_DIR,\"cleaned-covid-valid.tsv\"),sep=\"\\t\",index=False, header=False)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRuYUkbYBe_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.random.uniform(1, 0.05, size=(len(grouped_questions_df))) # "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMbWDodyRlAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# # randchoice k indices without replacement\n",
        "# train_covid_df, valid_covid_df = train_test_split(relevant_df, test_size=0.05, random_state=0)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kjtpMRmPc8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_COVID_EXAMPLES = {\"train\":len(unique_train_df), \"validation\":len(unique_test_df)}"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdzduhsDPgm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5c7e492-c17c-4a23-c19a-3745b85edb7f"
      },
      "source": [
        "NUM_COVID_EXAMPLES"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 169, 'validation': 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8ScXhEmdMel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(os.path.join(DATA_DIR,\"abc.txt\"), \"w\") as file:\n",
        "#   file.write(\"hello\\n\")\n",
        "\n",
        "with open(\"my_file.txt\", \"w\") as file:\n",
        "  file.write(\"akf\\n\")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9c0ZFaedYPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with tf.io.gfile.GFile(os.path.join(DATA_DIR,\"abc.txt\"), \"w\") as file:\n",
        "#   file.write(\"hello\\n\")\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzAXKuuoZRb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with tf.io.gfile.GFile(covid_qa_tsv_path[\"train\"], \"r\") as file:\n",
        "#   for line in file:\n",
        "#     print(line)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R-Ja8akCX1dR"
      },
      "source": [
        "Next, we define a function to load the TSV data as a `tf.data.Dataset` in TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KPOteeqctpzw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a4b9e4d7-3f5a-4127-f8fa-0c3631284a0a"
      },
      "source": [
        "def nq_dataset_fn(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split]) #add in the specific examples you want here as well \n",
        "  # Split each \"<question>\\t<answer>\" example into (question, answer) tuple.\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"\", \"\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  # Map each tuple to a {\"question\": ... \"answer\": ...} dict.\n",
        "  ds = ds.map(lambda *ex: dict(zip([\"question\", \"answer\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_fn(\"validation\").take(1)):\n",
        "  # print(ex)\n",
        "  print(len(ex))\n",
        "  # print(ex[\"question\"])\n",
        "  # print(ex[\"answer\"])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccbz4tzqecTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9f4fa858-1b16-4451-d9ec-21a65ac72ba2"
      },
      "source": [
        "covid_qa_tsv_path"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 'gs://t5-open-qa-bucket/data/cleaned-covid-train.tsv',\n",
              " 'validation': 'gs://t5-open-qa-bucket/data/cleaned-covid-valid.tsv'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzs9nB-DeG9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f337c776-e85b-4538-d6dd-85a627628624"
      },
      "source": [
        "def covid_dataset_fn(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(covid_qa_tsv_path[split]) #add in the specific examples you want here as well \n",
        "  # Split each \"<question>\\t<answer>\" example into (question, answer) tuple.\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"\", \"\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  # Map each tuple to a {\"question\": ... \"answer\": ...} dict.\n",
        "  ds = ds.map(lambda *ex: dict(zip([\"question\", \"answer\"], ex)))\n",
        "  \n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(covid_dataset_fn(\"train\").take(5)):\n",
        "  # print(ex)\n",
        "  print(len(ex))\n",
        "  # print(ex[\"question\"])\n",
        "  # print(ex[\"answer\"])\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPOQ9DGPT4t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = covid_dataset_fn(\"train\")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMnCYdkDT70d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# with tf.session() as sess:\n",
        "#   for ex in test_ds:\n",
        "#     print(ex)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MCUYT7JmX9Tj"
      },
      "source": [
        "Now, we write a preprocess function to convert the examples in the `tf.data.Dataset` into a text-to-text format, with both `inputs` and `targets` fields. The preprocessor also normalizes the text by lowercasing it and removing quotes since the answers are sometimes formatted in odd ways. Finally, we prepend 'trivia question:' to the inputs so that the model knows what task it's trying to solve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x8tNn6HMYLMb",
        "colab": {}
      },
      "source": [
        "def trivia_preprocessor(ds):\n",
        "  def normalize_text(text):\n",
        "    \"\"\"Lowercase and remove quotes from a TensorFlow string.\"\"\"\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.regex_replace(text,\"'(.*)'\", r\"\\1\")\n",
        "    return text\n",
        "\n",
        "  def to_inputs_and_targets(ex):\n",
        "    \"\"\"Map {\"question\": ..., \"answer\": ...}->{\"inputs\": ..., \"targets\": ...}.\"\"\"\n",
        "    return {\n",
        "        \"inputs\":\n",
        "             tf.strings.join(\n",
        "                 [\"trivia question: \", normalize_text(ex[\"question\"])]),\n",
        "        \"targets\": normalize_text(ex[\"answer\"])\n",
        "    }\n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gm1Pm2aRZ9Ow"
      },
      "source": [
        "Finally, we put everything together to create a `Task`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yJyRavOpZ7UW",
        "colab": {}
      },
      "source": [
        "t5.data.TaskRegistry.add(\n",
        "    \"nq_context_free\",\n",
        "    # Supply a function which returns a tf.data.Dataset.\n",
        "    dataset_fn=nq_dataset_fn,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    # Supply a function which preprocesses text from the tf.data.Dataset.\n",
        "    text_preprocessor=[trivia_preprocessor],\n",
        "    # Lowercase targets before computing metrics.\n",
        "    postprocess_fn=t5.data.postprocessors.lower_text, \n",
        "    # We'll use accuracy as our evaluation metric.\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    # Not required, but helps for mixing and auto-caching.\n",
        "    num_input_examples=num_nq_examples\n",
        ")"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qe4o_0jFbP-p"
      },
      "source": [
        "Let's look at a few pre-processed examples from the validation set. Note they contain both the tokenized (integer) and plain-text inputs and targets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I64TqHGxbOJ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "d3a18841-0d35-4f29-ffa3-53a8bc25e6e4"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"nq_context_free\")\n",
        "ds = nq_task.get_dataset(split=\"validation\", sequence_length={\"inputs\": 128, \"targets\": 32})\n",
        "print(\"A few preprocessed validation examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/data/utils.py:273: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  return dataset.map(my_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed validation examples...\n",
            "{'inputs_plaintext': b'trivia question: how many medals did austria win in the 2011 alpine skiing world championships?', 'inputs': array([22377,   822,    10,   149,   186,  9365,     7,   410,   185,\n",
            "       23387,  1369,    16,     8,  2722,   491,  3180,    15, 18483,\n",
            "         296, 10183,     7,    58,     1]), 'targets_plaintext': b'8', 'targets': array([505,   1])}\n",
            "{'inputs_plaintext': b'trivia question: who is in charge of ratifying treaties in the us?', 'inputs': array([22377,   822,    10,   113,    19,    16,  1567,    13,     3,\n",
            "        1795,  8587,  2665,   725,    16,     8,   178,    58,     1]), 'targets_plaintext': b'the president', 'targets': array([   8, 2753,    1])}\n",
            "{'inputs_plaintext': b'trivia question: where is the host file located in windows server 2008 r2?', 'inputs': array([22377,   822,    10,   213,    19,     8,  2290,  1042,  1069,\n",
            "          16,  3196,  2460,  2628,     3,    52,   357,    58,     1]), 'targets_plaintext': b'% systemroot% \\\\ system32 \\\\ drivers \\\\ etc \\\\ hosts', 'targets': array([    3,  1454,   358, 18951,  1454,     3,     2,   358,  2668,\n",
            "           3,     2,  3863,     3,     2,   672,     3,     2,  9855,\n",
            "           1])}\n",
            "{'inputs_plaintext': b'trivia question: what is the coldest it has ever been in antarctica?', 'inputs': array([22377,   822,    10,   125,    19,     8,  2107,   222,    34,\n",
            "          65,   664,   118,    16,     3,   288,  4667,  7439,    58,\n",
            "           1]), 'targets_plaintext': b'\\xe2\\x88\\x92 89.2 \\xc2\\xb0 c (\\xe2\\x88\\x92 128.6 \\xc2\\xb0 f)', 'targets': array([   3,    2,    3, 3914,    5,  357,    3, 1956,    3,   75,   41,\n",
            "          2,  209, 2577,    5,  948,    3, 1956,    3,   89,   61,    1])}\n",
            "{'inputs_plaintext': b'trivia question: the most common form of megalithic architecture in europe is?', 'inputs': array([22377,   822,    10,     8,   167,  1017,   607,    13, 13950,\n",
            "       18800,   447,  4648,    16,     3, 28188,    19,    58,     1]), 'targets_plaintext': b'the portal tomb', 'targets': array([    8,  8948, 10351,     1])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G1ktIEGePdBr"
      },
      "source": [
        "**Note**: Instead of defining `nq_dataset_fn` and above, we also could have used the `TextLineTask` class with the `parse_tsv` preprocessor for equivalent results as follows:\n",
        "\n",
        "```py\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"nq_context_free\",\n",
        "    t5.data.TextLineTask,\n",
        "    split_to_filepattern=nq_tsv_path,\n",
        "    text_preprocessor=[\n",
        "      functools.partial(\n",
        "          t5.data.preprocessors.parse_tsv,\n",
        "          field_names=[\"question\", \"answer\"]),\n",
        "      trivia_preprocessor\n",
        "    ],\n",
        "    postprocess_fn=t5.data.postprocessors.lower_text, \n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5Icz9grQKX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t5.data.TaskRegistry.remove(\"covid_context_free\")"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nMfkNZtPIVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t5.data.TaskRegistry.add(\n",
        "    \"covid_context_free\",\n",
        "    # Supply a function which returns a tf.data.Dataset.\n",
        "    dataset_fn=covid_dataset_fn,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    # Supply a function which preprocesses text from the tf.data.Dataset.\n",
        "    text_preprocessor=[trivia_preprocessor],\n",
        "    # Lowercase targets before computing metrics.\n",
        "    postprocess_fn=t5.data.postprocessors.lower_text, \n",
        "    # We'll use accuracy as our evaluation metric.\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    # Not required, but helps for mixing and auto-caching.\n",
        "    num_input_examples=NUM_COVID_EXAMPLES\n",
        ")"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQZaT2u7PtbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "7c972de7-4edc-4217-e3b1-e988c843d44b"
      },
      "source": [
        "covid_qa_task = t5.data.TaskRegistry.get(\"covid_context_free\")\n",
        "covid_ds = covid_qa_task.get_dataset(split=\"validation\", sequence_length={\"inputs\": 128, \"targets\": 32})\n",
        "print(\"A few preprocessed validation examples...\")\n",
        "for ex in tfds.as_numpy(covid_ds.take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/data/utils.py:273: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  return dataset.map(my_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed validation examples...\n",
            "{'inputs_plaintext': b'trivia question: are screening tests effective if you don\\xe2\\x80\\x99t have symptoms?', 'inputs': array([22377,   822,    10,    33,  7468,  3830,  1231,     3,    99,\n",
            "          25,   278,    22,    17,    43,  3976,    58,     1]), 'targets_plaintext': b' it cannot be confirmed that tests done on people who are asymptomatic are conclusive,', 'targets': array([   34,  1178,    36,  5899,    24,  3830,   612,    30,   151,\n",
            "         113,    33,     3,     9, 18018,  6049,    33, 16129,     7,\n",
            "         757,     6,     1])}\n",
            "{'inputs_plaintext': b'trivia question: what can national veterinary services do with regards to companion animals?', 'inputs': array([22377,   822,    10,   125,    54,  1157,     3, 22987,   364,\n",
            "         103,    28,  9544,    12,  9663,  3127,    58,     1]), 'targets_plaintext': b'public health and veterinary services should work togethe', 'targets': array([  452,   533,    11,     3, 22987,   364,   225,   161,    12,\n",
            "         397,   532,     1])}\n",
            "{'inputs_plaintext': b'trivia question: what types of medications and health supplies should i have on hand for an extended stay at home?', 'inputs': array([22377,   822,    10,   125,  1308,    13, 11208,    11,   533,\n",
            "        4471,   225,     3,    23,    43,    30,   609,    21,    46,\n",
            "        4760,  1049,    44,   234,    58,     1]), 'targets_plaintext': b'medical and health supplies ', 'targets': array([1035,   11,  533, 4471,    1])}\n",
            "{'inputs_plaintext': b'trivia question: how does the virus spread?', 'inputs': array([22377,   822,    10,   149,   405,     8,  6722,  3060,    58,\n",
            "           1]), 'targets_plaintext': b'from respiratory droplets that become airborne when someone, who is infected, sneezes or coughs nearby. ', 'targets': array([   45, 19944,  2328,  7677,    24,   582,   799, 12940,   116,\n",
            "         841,     6,   113,    19,    16,    89,  7633,     6,     3,\n",
            "           7,    29,    15,  2187,     7,    42, 19222,     7,  4676,\n",
            "           5,     1])}\n",
            "{'inputs_plaintext': b'trivia question: what can i do if i do not receive a record of employment or termination of employment?', 'inputs': array([22377,   822,    10,   125,    54,     3,    23,   103,     3,\n",
            "          99,     3,    23,   103,    59,   911,     3,     9,  1368,\n",
            "          13,  4311,    42, 18739,    13,  4311,    58,     1]), 'targets_plaintext': b'your employer must pay you an indemnity equal to your usual salary for the duration (or remaining duration) ', 'targets': array([   39,  6152,   398,   726,    25,    46, 11468,    29,   485,\n",
            "        4081,    12,    39,  4680,  9090,    21,     8,  8659,    41,\n",
            "         127,  4080,  8659,    61,     1])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y4_1gpcK9i3W"
      },
      "source": [
        "## TriviaQA\n",
        "\n",
        "A second dataset we will use is related to [TriviaQA](https://nlp.cs.washington.edu/triviaqa/). It is also intended for reading comprehension, but, once again, we will modify the task here by ignoring the provided context.\n",
        "\n",
        "Since the dataset has been imported into [TensorFlow Datasets (TFDS)](https://www.tensorflow.org/datasets/catalog/trivia_qa), we can let it handle the data parsing for us. It will take a few minutes to download and preprocess the first time, but we'll be able to access it instantly from our data directory afterward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQTQHS94Z0Tq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "f06e287e-6920-43ea-8eb4-2936edad3b89"
      },
      "source": [
        "ds = tfds.load(\n",
        "    \"trivia_qa/unfiltered.nocontext\",\n",
        "    data_dir=DATA_DIR,\n",
        "    # Download data locally for preprocessing to avoid using GCS space.\n",
        "    download_and_prepare_kwargs={\"download_dir\": \"./downloads\"})\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(ds[\"validation\"].take(2)):\n",
        "  print(ex)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Load dataset info from gs://t5-open-qa-bucket/data/trivia_qa/unfiltered.nocontext/1.1.0\n",
            "INFO:absl:Reusing dataset trivia_qa (gs://t5-open-qa-bucket/data/trivia_qa/unfiltered.nocontext/1.1.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split None, from gs://t5-open-qa-bucket/data/trivia_qa/unfiltered.nocontext/1.1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'answer': {'aliases': array([b'Torquemada (disambiguation)', b'Torquemada'], dtype=object), 'matched_wiki_entity_name': b'', 'normalized_aliases': array([b'torquemada', b'torquemada disambiguation'], dtype=object), 'normalized_matched_wiki_entity_name': b'', 'normalized_value': b'torquemada', 'type': b'WikipediaEntity', 'value': b'Torquemada'}, 'entity_pages': {'doc_source': array([], dtype=object), 'filename': array([], dtype=object), 'title': array([], dtype=object), 'wiki_context': array([], dtype=object)}, 'question': b'In 1483, who was appointed the first grand inquisitor of the Spanish Inquisition?', 'question_id': b'qw_16011', 'question_source': b'http://www.quizwise.com/', 'search_results': {'description': array([], dtype=object), 'filename': array([], dtype=object), 'rank': array([], dtype=int32), 'search_context': array([], dtype=object), 'title': array([], dtype=object), 'url': array([], dtype=object)}}\n",
            "{'answer': {'aliases': array([b'Austerlitz (disambiguation)', b'Austerlitz', b'AUSTERLITZ'],\n",
            "      dtype=object), 'matched_wiki_entity_name': b'', 'normalized_aliases': array([b'austerlitz', b'austerlitz disambiguation'], dtype=object), 'normalized_matched_wiki_entity_name': b'', 'normalized_value': b'austerlitz', 'type': b'WikipediaEntity', 'value': b'AUSTERLITZ'}, 'entity_pages': {'doc_source': array([], dtype=object), 'filename': array([], dtype=object), 'title': array([], dtype=object), 'wiki_context': array([], dtype=object)}, 'question': b'Which celebrated battle was fought near Brno on 2nd December 1805?', 'question_id': b'dpql_4053', 'question_source': b'https://derbyshirepubquizleague.wordpress.com/', 'search_results': {'description': array([], dtype=object), 'filename': array([], dtype=object), 'rank': array([], dtype=int32), 'search_context': array([], dtype=object), 'title': array([], dtype=object), 'url': array([], dtype=object)}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gq5U_rjDb1bn"
      },
      "source": [
        "As with Natural Questions, we need to preprocess the raw examples into `inputs` and `targets` features. We can reuse the `trivia_preprocessor` above, but first we need to convert the TriviaQA examples into the correct format, ignoring the fields we don't need for our task.\n",
        "\n",
        "We'll then define our `Task` and print out a few preprocessed examples from the validation set.\n",
        "\n",
        "Note that we do not need to specify the splits or number of examples since that information is provided by TFDS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6rU32DjyeLuL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "11f4958f-1b3b-4844-d3fd-ae360c0b7d8f"
      },
      "source": [
        "def tiviaqa_extract_qa(ds):\n",
        "  def exract_qa(ex):\n",
        "    return {\n",
        "        \"question\": ex[\"question\"],\n",
        "        \"answer\": ex[\"answer\"][\"value\"]\n",
        "    }\n",
        "  return ds.map(exract_qa, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"triviaqa_context_free\",\n",
        "    # A TfdsTask takes in a TFDS name instead of a tf.data.Dataset function.\n",
        "    t5.data.TfdsTask,\n",
        "    tfds_name=\"trivia_qa/unfiltered.nocontext:1.1.0\",\n",
        "    tfds_data_dir=DATA_DIR,\n",
        "    text_preprocessor=[tiviaqa_extract_qa, trivia_preprocessor],\n",
        "    postprocess_fn=t5.data.postprocessors.lower_text,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy]\n",
        ")\n",
        "\n",
        "# Load and print a few examples.\n",
        "triviaqa_task = t5.data.TaskRegistry.get(\"triviaqa_context_free\")\n",
        "ds = triviaqa_task.get_dataset(split=\"validation\", sequence_length={\"inputs\": 128, \"targets\": 32})\n",
        "print(\"A few preprocessed validation examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Load dataset info from gs://t5-open-qa-bucket/data/trivia_qa/unfiltered.nocontext/1.1.0\n",
            "INFO:absl:Reusing dataset trivia_qa (gs://t5-open-qa-bucket/data/trivia_qa/unfiltered.nocontext/1.1.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split validation, from gs://t5-open-qa-bucket/data/trivia_qa/unfiltered.nocontext/1.1.0\n",
            "/usr/local/lib/python3.6/dist-packages/t5/data/utils.py:273: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  return dataset.map(my_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
            "INFO:absl:Load dataset info from gs://t5-open-qa-bucket/data/trivia_qa/unfiltered.nocontext/1.1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed validation examples...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wlghm_3rAd-M"
      },
      "source": [
        "## Dataset Mixture\n",
        "\n",
        "We now create a `Mixture` from the above `Tasks`, which we will fine-tune on.\n",
        "\n",
        "There are different ways to automatically set the rate (for example, based on the number of examples using `rate_num_examples`), but we will just hardcode an equal mixture for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zgs-s3eDAU37",
        "colab": {}
      },
      "source": [
        "t5.data.MixtureRegistry.remove(\"trivia_all\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"trivia_all\",\n",
        "    [\"nq_context_free\", \"triviaqa_context_free\", \"covid_context_free\"],\n",
        "     default_rate=1.0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CUkorodCENGw"
      },
      "source": [
        "# Transferring to new Tasks\n",
        "\n",
        "We are now ready to fine-tune one of the pre-trained T5 models on our new mixture of closed-book QA tasks.\n",
        "\n",
        "First, we'll instantiate a `Model` object using the model size of your choice. Note that larger models are slower to train and use but will likely achieve higher accuracy. You also may be able to increase accuracy by training longer with more `FINETUNE_STEPS` below.\n",
        "\n",
        "\n",
        "## Caveats\n",
        "\n",
        "* Due to its memory requirements, you will not be able to train the `11B` parameter model on the TPU provided by Colab. Instead, you will need to fine-tune inside of a GCP instance (see [README](https://github.com/google-research/text-to-text-transfer-transformer/)).\n",
        "* Due to the checkpoint size, you will not be able use the 5GB GCS free tier for the `3B` parameter models. You will need at least 25GB of space, which you can purchase with your $300 of initial credit on GCP.\n",
        "* While `large` can achieve decent results, it is recommended that you fine-tune at least the `3B` parameter model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "syte5n0nnMOC"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "yGQ-zpgy3raf",
        "colab": {}
      },
      "source": [
        "MODEL_SIZE = \"large\" #@param[\"small\", \"base\", \"large\", \"3B\", \"11B\"]\n",
        "# Public GCS path for T5 pre-trained model checkpoints\n",
        "BASE_PRETRAINED_DIR = \"gs://t5-data/pretrained_models\"\n",
        "PRETRAINED_DIR = os.path.join(BASE_PRETRAINED_DIR, MODEL_SIZE)\n",
        "MODEL_DIR = os.path.join(MODELS_DIR, MODEL_SIZE)\n",
        "\n",
        "if ON_CLOUD and MODEL_SIZE == \"3B\":\n",
        "  tf.logging.warn(\n",
        "      \"The `3B` model is too large to use with the 5GB GCS free tier. \"\n",
        "      \"Make sure you have at least 25GB on GCS before continuing.\"\n",
        "  )\n",
        "elif ON_CLOUD and MODEL_SIZE == \"11B\":\n",
        "  raise ValueError(\n",
        "      \"The `11B` parameter is too large to fine-tune on the `v2-8` TPU \"\n",
        "      \"provided by Colab. Please comment out this Error if you're running \"\n",
        "      \"on a larger TPU.\"\n",
        "  )\n",
        "\n",
        "# Set parallelism and batch size to fit on v2-8 TPU (if possible).\n",
        "# Limit number of checkpoints to fit within 5GB (if possible).\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "# The models from our paper are based on the Mesh Tensorflow Transformer.\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 128, \"targets\": 32},\n",
        "    learning_rate_schedule=0.003,\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dInuo63ZQrFi"
      },
      "source": [
        "Before we continue, let's load a [TensorBoard](https://www.tensorflow.org/tensorboard) visualizer so that we can keep monitor our progress. The page should automatically update as fine-tuning and evaluation proceed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M5mPyYATNsVT",
        "colab": {}
      },
      "source": [
        "# if ON_CLOUD:\n",
        "#   %reload_ext tensorboard\n",
        "#   import tensorboard as tb\n",
        "# tb.notebook.start(\"--logdir \" + MODELS_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DZhAd0U_4B_o"
      },
      "source": [
        "## Fine-tune\n",
        "\n",
        "We are now ready to fine-tune our model. This will take a while (~2 hours with default settings), so please be patient! The larger the model and more `FINETUNE_STEPS` you use, the longer it will take.\n",
        "\n",
        "Don't worry, you can always come back later and increase the number of steps, and it will automatically pick up where you left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V7t7a25LBTj9",
        "colab": {}
      },
      "source": [
        "FINETUNE_STEPS =  25000#@param {type: \"integer\"}\n",
        "\n",
        "model.finetune(\n",
        "    mixture_or_task_name=\"trivia_all\",\n",
        "    pretrained_model_dir=PRETRAINED_DIR,\n",
        "    finetune_steps=FINETUNE_STEPS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFXZENjKpEtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-pFvyrHmm6Mx"
      },
      "source": [
        "## Expected Results [SPOILER ALERT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i_-7qYemnEHl"
      },
      "source": [
        "Below are the expected accuracies on the Natural Question (NQ) and TriviQA validation sets for various model sizes. The full 11B model produces the exact text of the answer 34.5% and 25.1% of the time on TriviaQA and NQ, respectively. The 3B parameter model, which is the largest that can be trained with a free Cloud TPU in Colab, achieves 29.7% and 23.7%, respectively.\n",
        "\n",
        "In reality, the model performs better than this since requiring exact match is too strict of a metric, as you’ll see in the examples below. This helps to explain why the model appears to perform better on TriviaQA than NQ, as the latter tends to include more long-form answers extracted from the context.\n",
        "\n",
        "Please see our [paper on closed-book QA](https://tiny.cc/t5-qa) where achieved even better results.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/t5-data/assets/t5_trivia_expected.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eYeciUZ_D7T2"
      },
      "source": [
        "## Evaluate\n",
        "\n",
        "We now evaluate on the validation sets of the tasks in our mixture. Accuracy results will be logged and added to the TensorBoard above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bz6CJRHzNfd3",
        "colab": {}
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = train_batch_size * 4\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"trivia_all\",\n",
        "    checkpoint_steps=\"all\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLjwskjPCF1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"OK\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZIitCkPRkkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_covid_df[train_covid_df[\"question\"].str.contains(\"start\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRJIybaPskcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_covid_df[train_covid_df[\"question\"].str.contains(\"pool\")] # ensure that we FORCE the QA pairs to disjoin from one another"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "92dClA1SWwIx"
      },
      "source": [
        "Let's look at a few random predictions from the validation sets. Note that we measure accuracy based on an *exact match* of the predicted answer and the ground-truth answer. As a result, some of the answers are semantically correct but are counted wrong by the exact match score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-FuqHRuvxOct",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def print_random_predictions(task_name, n=10):\n",
        "  \"\"\"Print n predictions from the validation split of a task.\"\"\"\n",
        "  # Grab the dataset for this task.\n",
        "  ds = t5.data.TaskRegistry.get(task_name).get_dataset(\n",
        "      split=\"validation\",\n",
        "      sequence_length={\"inputs\": 128, \"targets\": 128},\n",
        "      shuffle=False)\n",
        "\n",
        "  def _prediction_file_to_ckpt(path):\n",
        "    \"\"\"Extract the global step from a prediction filename.\"\"\"\n",
        "    return int(path.split(\"_\")[-2])\n",
        "\n",
        "  # Grab the paths of all logged predictions.\n",
        "  prediction_files = tf.io.gfile.glob(\n",
        "      os.path.join(\n",
        "          MODEL_DIR,\n",
        "          \"validation_eval/%s_*_predictions\" % task_name))\n",
        "  # Get most recent prediction file by sorting by their step.\n",
        "  latest_prediction_file = sorted(\n",
        "      prediction_files, key=_prediction_file_to_ckpt)[-1]\n",
        "\n",
        "  # Collect (inputs, targets, prediction) from the dataset and predictions file\n",
        "  results = []\n",
        "  with tf.io.gfile.GFile(latest_prediction_file) as preds:\n",
        "    for ex, pred in zip(tfds.as_numpy(ds), preds):\n",
        "      results.append((tf.compat.as_text(ex[\"inputs_plaintext\"]),\n",
        "                      tf.compat.as_text(ex[\"targets_plaintext\"]),\n",
        "                      pred.strip()))\n",
        "\n",
        "  print(\"<== Random predictions for %s using checkpoint %s ==>\\n\" %\n",
        "        (task_name, \n",
        "         _prediction_file_to_ckpt(latest_prediction_file)))\n",
        "\n",
        "  for inp, tgt, pred in random.choices(results, k=10):\n",
        "    print(\"Input:\", inp)\n",
        "    print(\"Target:\", tgt)\n",
        "    print(\"Prediction:\", pred)\n",
        "    print(\"Counted as Correct?\", tgt == pred)\n",
        "    print()\n",
        "\n",
        "# print_random_predictions(\"triviaqa_context_free\")\n",
        "# print_random_predictions(\"nq_context_free\")\n",
        "print_random_predictions(\"covid_context_free\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lWxnihUpYAa",
        "colab_type": "text"
      },
      "source": [
        "# Predict on given questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bah85cSpa-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PARSA_QA_PATH = os.path.join(DATA_DIR, \"cleaned_CORD19_test_QA_df.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U1u33n4_j8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROHAN_QA_PATH = os.path.join(DATA_DIR, \"df_0.75_qa_dlr.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toGYkkalcHJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cLhvkficPLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kaa1Cn9Vp6P1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "additional_COVID_QA_df = pd.read_csv(PARSA_QA_PATH) # cloud read by the pandas\n",
        "annotated_df = pd.read_csv(ROHAN_QA_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9vslTcziRKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4i0n0QNCnzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "annotated_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6OPYDBeAUay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_annotated_df = annotated_df[annotated_df[\"Validity\"]==1] #only select the valid examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtfuecUOAjDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_annotated_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3w9RHWlAgA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate the answers now, for all of them"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pADkqSDsK-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "additional_COVID_QA_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnGn8c4LqBUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# METHOD 1\n",
        "# extract only the questions\n",
        "additional_COVID_QA_df[\"question\"]\n",
        "covid_predict_inputs_path = os.path.join(MODEL_DIR, \"predict_inputs_COVID_QA.txt\")\n",
        "covid_predict_outputs_path = os.path.join(MODEL_DIR, \"predict_outputs_COVID_QA.txt\")\n",
        "with tf.io.gfile.GFile(covid_predict_inputs_path, \"w\") as f:\n",
        "  for idx, row in additional_COVID_QA_df.iterrows():\n",
        "    q = row[\"question\"]\n",
        "    # print(q)\n",
        "    f.write(\"trivia question: %s\\n\" % q.lower()) #TODO: can also invoke the preprocess from earlier\n",
        "\n",
        "model.batch_size = 256  # Min size for small model on v2-8 with parallelism 1.\n",
        "model.predict(\n",
        "    input_file=covid_predict_inputs_path,\n",
        "    output_file=covid_predict_outputs_path,\n",
        "    # Select the most probable output token at each step.\n",
        "    temperature=0,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9d_uVneHo6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# METHOD 2\n",
        "# use the unique_test_df only\n",
        "# drawbacks: include the fact that the answer might not be in the span. We would need a new way of evaluating it !"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tHNH01wuLhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pb8OOzrW40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now, we simply get the predict outputs from the list of paths we provided"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ59d-lzsW0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_files = sorted(tf.io.gfile.glob(covid_predict_outputs_path + \"*\"))\n",
        "print(\"\\nPredictions using checkpoint %s:\\n\" % prediction_files[-1].split(\"-\")[-1])\n",
        "with tf.io.gfile.GFile(prediction_files[-1]) as f:\n",
        "  answers = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLGxrBDqvT3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wT45Z63ktQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "additional_COVID_QA_df[\"t5_answers\"] = answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4wkiQ2jl3eI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "additional_COVID_QA_df.to_csv(os.path.join(DATA_DIR, \"results\", \"COMBINED_T5_answers.csv\"))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSvDAy6cmK4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "additional_COVID_QA_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FltVYmhsl_mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Now just compute lengths and such \n",
        "t5_lengths = [len(seq.split()) for seq in additional_COVID_QA_df[\"t5_answers\"].tolist()]\n",
        "gt_lengths = [len(valid_ans.split()) for valid_ans in additional_COVID_QA_df[\"answer\"].tolist()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLS6ji1fmOcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(t5_lengths, label=\"T5 answer lengths\", alpha=0.75)\n",
        "ax.hist(gt_lengths, label=\"Ground truth answer lengths\", alpha=0.75)\n",
        "ax.set_title(\"Distribution of answer lengths\")\n",
        "ax.set_xlabel(\"Number of tokens in answer\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "# ax.set_xlim(0,60)\n",
        "\n",
        "ax.legend()\n",
        "plt.savefig(\"LengthDistributionComparison_COVID_GQA\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn5nm50ynXhe",
        "colab_type": "text"
      },
      "source": [
        "# Predictions (2nd wave)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsiPBxQqnWsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "sim_df = pd.read_csv(os.path.join(DATA_DIR,\"active_learning\", \"sim_df_75.csv\"))\n",
        "sme_df = pd.read_csv(os.path.join(DATA_DIR,\"active_learning\", \"sme_rule_based.csv\"))\n",
        "final_sim_df = pd.read_csv(os.path.join(DATA_DIR,\"active_learning\", \"df_qa_sim_positive_labels.csv\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBOYesS6YcAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sme_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmdrbF6roaok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_sim_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOlzp0j6ovNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sme_df[\"questions\"].head().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8yPO33An35i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "covid_predict_inputs_sim_df_path = os.path.join(MODEL_DIR, \"predict_inputs_sim_df_75.txt\")\n",
        "covid_predict_outputs_sim_path = os.path.join(MODEL_DIR, \"predict_outputs_sim_df_75.txt\")\n",
        "with tf.io.gfile.GFile(covid_predict_inputs_sim_df_path, \"w\") as f:\n",
        "  for idx, row in sim_df.iterrows():\n",
        "    q = row[\"title\"]\n",
        "    # print(q)\n",
        "    f.write(\"trivia question: %s\\n\" % q.lower()) #TODO: can also invoke the preprocess from earlier\n",
        "\n",
        "model.batch_size = 1024  # Min size for small model on v2-8 with parallelism 1.\n",
        "model.predict(\n",
        "    input_file=covid_predict_inputs_sim_df_path,\n",
        "    output_file=covid_predict_outputs_sim_path,\n",
        "    # Select the most probable output token at each step.\n",
        "    temperature=0,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8vShX_20C_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "covid_predict_inputs_sim_df_path_new = os.path.join(MODEL_DIR, \"predict_inputs_df_qa_sim_positive_labels.txt\")\n",
        "covid_predict_outputs_sim_df_path_new = os.path.join(MODEL_DIR, \"predict_outputs_df_qa_sim_positive_labels.txt\")\n",
        "with tf.io.gfile.GFile(covid_predict_inputs_sim_df_path_new, \"w\") as f:\n",
        "  for idx, row in final_sim_df.iterrows():\n",
        "    q = row[\"question\"]\n",
        "    f.write(\"trivia question: %s\\n\" % q.lower()) #TODO: can also invoke the preprocess from earlier\n",
        "\n",
        "model.batch_size = 1024  # Min size for small model on v2-8 with parallelism 1.\n",
        "model.predict(\n",
        "    input_file=covid_predict_inputs_sim_df_path_new,\n",
        "    output_file=covid_predict_outputs_sim_df_path_new,\n",
        "    # Select the most probable output token at each step.\n",
        "    temperature=0,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JqSGdNcogwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_predict_inputs_sme_path = os.path.join(MODEL_DIR, \"predict_inputs_sme_rule_based.txt\")\n",
        "covid_predict_outputs_sme_path = os.path.join(MODEL_DIR, \"predict_outputs_sme_rule_based.txt\")\n",
        "with tf.io.gfile.GFile(covid_predict_inputs_sme_path, \"w\") as f:\n",
        "  for idx, row in sme_df.iterrows():\n",
        "    q = row[\"questions\"]\n",
        "    print(q)\n",
        "    f.write(\"trivia question: %s\\n\" % q.lower()) #TODO: can also invoke the preprocess from earlier\n",
        "\n",
        "model.batch_size = 1024  # Min size for small model on v2-8 with parallelism 1.\n",
        "model.predict(\n",
        "    input_file=covid_predict_inputs_sme_path,\n",
        "    output_file=covid_predict_outputs_sme_path,\n",
        "    # Select the most probable output token at each step.\n",
        "    temperature=0,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLvSe9a4vgZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"OK\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTk5GeITyKOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tying together predictions from both"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHm76UCMBKBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJUcUNdSyqjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_predict_outputs_sme_path + \"-1025700\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkwg9F0D0XlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need a google cloud read!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf1rJLyMyMX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.io.gfile.GFile((covid_predict_outputs_sme_path + \"-1025700\")) as answers, tf.io.gfile.GFile((covid_predict_inputs_sme_path )) as questions:\n",
        "  list_answers = answers.readlines()\n",
        "  list_questions = questions.readlines()\n",
        "  sme_df = pd.DataFrame(data={\"questions\":list_questions , \"answers\": list_answers} )\n",
        "  # print(len(), len(questions.readlines()))\n",
        "\n",
        "    \n",
        "    #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHt7qEtI16F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sme_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJEqnIktWXzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_predict_inputs_sim_df_path_new\n",
        "covid_predict_outputs_sim_df_path_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLyBbgZ1PqTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.io.gfile.GFile((covid_predict_outputs_sim_df_path_new + \"-1025700\")) as answers, tf.io.gfile.GFile((covid_predict_inputs_sim_df_path_new )) as questions:\n",
        "  list_answers = answers.readlines()\n",
        "  list_questions = questions.readlines()\n",
        "  new_sim_df = pd.DataFrame(data={\"questions\":list_questions , \"answers\": list_answers} )\n",
        "  # print(len(), len(questions.readlines()))\n",
        "\n",
        "    \n",
        "    #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdgUb18u2nst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sme_out_path = os.path.join(DATA_DIR, \"sme.csv\")\n",
        "sim_out_path = os.path.join(DATA_DIR, \"sim.csv\")\n",
        "new_sim_out_path = os.path.join(DATA_DIR, \"new_sim.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvSZ0u8K2fuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sme_df.to_csv(sme_out_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej8xX76m2yVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_sim_df.to_csv(new_sim_out_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVBsae5P1P4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.io.gfile.GFile((covid_predict_outputs_sim_path + \"-1025700\")) as answers, tf.io.gfile.GFile((covid_predict_inputs_sim_df_path )) as questions:\n",
        "  list_answers = answers.readlines()\n",
        "  list_questions = questions.readlines()\n",
        "  sim_df = pd.DataFrame(data={\"questions\":list_questions , \"answers\": list_answers} )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuMkK97Q1gye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sim_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh5bLf4r206T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sim_df.to_csv(sim_out_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNdcRNuyvlRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "additional_COVID_QA_df[\"t5_answers\"] = answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-hTFaDku41M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HVDUEcxvs_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "additional_COVID_QA_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1c_EEdtuv-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "additional_COVID_QA_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFw5v3IFvuSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compare the answers with hilary and Yoona's work\n",
        "# COVID_GQA_PATH = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBS_dUtCv_z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T5_QA_PATH = os.path.join(DATA_DIR, \"T5_CORD19_cleaned_test_QA_results_df.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioMDPu59v6KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "additional_COVID_QA_df.to_csv(T5_QA_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtXA5iFJF9IP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the addtional_COVID_QA_df to be the test set only\n",
        "# additional_COVID_QA_df = unique_test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl5n1dQ462IU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def get_exact_match_score(prediction, ground_truth):\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "\n",
        "def get_f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def get_fuzzy_ratio(prediction, ground_truth):\n",
        "    return fuzz.ratio(normalize_answer(prediction), normalize_answer(ground_truth))\n",
        "\n",
        "\n",
        "\n",
        "exact_match_score = 0\n",
        "f1_score = 0\n",
        "total = len(additional_COVID_QA_df.index)\n",
        "\n",
        "for index, row in additional_COVID_QA_df.iterrows():\n",
        "    answer = normalize_answer(str(row['answer']))\n",
        "    predicted_answer = normalize_answer(str(row['t5_answers']))\n",
        "    \n",
        "    exact_match_score += get_exact_match_score(predicted_answer, answer)\n",
        "    f1_score += get_f1_score(predicted_answer, answer)\n",
        "\n",
        "f1_score = 100.0 * f1_score / total\n",
        "exact_match_score = 100.0 * exact_match_score / total\n",
        "print('F1 Score: ' + str(f1_score))\n",
        "print('Exact Match Score: ' + str(exact_match_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95KWpGx9gBc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "968P4hRycWeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZQgQ8B8cStX",
        "colab_type": "text"
      },
      "source": [
        "## The New SIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz4sPH7Pcrka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sim_QA = os.path.join(DATA_DIR, \"df_0.75_qa_dlr_positive_labels.csv\") \n",
        "sme_df_new = pd.read_csv(df_sim_QA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJZvWzZWdY63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sme_df_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz_PAD7vceFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_predict_inputs_sim_path_new = os.path.join(MODEL_DIR, \"predict_inputs_sme_rule_based.txt\")\n",
        "covid_predict_outputs_sim_path_new = os.path.join(MODEL_DIR, \"predict_outputs_sme_rule_based.txt\")\n",
        "with tf.io.gfile.GFile(covid_predict_inputs_sim_path_new, \"w\") as f:\n",
        "  for idx, row in sme_df_new.iterrows():\n",
        "    q = row[\"question\"]\n",
        "    print(q)\n",
        "    f.write(\"trivia question: %s\\n\" % q.lower()) #TODO: can also invoke the preprocess from earlier\n",
        "\n",
        "model.batch_size = 256  # Min size for small model on v2-8 with parallelism 1.\n",
        "model.predict(\n",
        "    input_file=covid_predict_inputs_sim_path_new,\n",
        "    output_file=covid_predict_outputs_sim_path_new,\n",
        "    # Select the most probable output token at each step.\n",
        "    temperature=0,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19VgLbPVc8nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.io.gfile.GFile((covid_predict_outputs_sim_path_new + \"-1025700\")) as answers, tf.io.gfile.GFile((covid_predict_inputs_sim_path_new )) as questions:\n",
        "  list_answers = answers.readlines()\n",
        "  list_questions = questions.readlines()\n",
        "  sim_df_new = pd.DataFrame(data={\"questions\":list_questions , \"answers\": list_answers} )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6rlXAzYhqO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypOxYe2Kehqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLKoLtnaeqEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RESULTS_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3J9RNTpe4CK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RESULTS_DIR + \"sim_df_new.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ij5L4DVeXPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sim_df_new.to_csv(os.path.join(RESULTS_DIR , \"sim_df_new.csv\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRq4oIHuAwy8",
        "colab_type": "text"
      },
      "source": [
        "# Predict on Manually annotated Valid Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnx9PQBbBkFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_annotated_df[\"questions\"].head().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5GZ1ScLA1lZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_predict_manual_valid_inputs_path = os.path.join(MODEL_DIR, \"predict_inputs_manual_df.txt\")\n",
        "covid_predict_manual_valid_outputs_path = os.path.join(MODEL_DIR, \"predict_outputs_manual_df.txt\")\n",
        "with tf.io.gfile.GFile(covid_predict_manual_valid_inputs_path, \"w\") as f:\n",
        "  for idx, row in valid_annotated_df.iterrows():\n",
        "    q = row[\"questions\"]\n",
        "    print(q)\n",
        "    f.write(\"trivia question: %s\\n\" % q.lower()) #TODO: can also invoke the preprocess from earlier\n",
        "\n",
        "model.batch_size = 256  # Min size for small model on v2-8 with parallelism 1.\n",
        "model.predict(\n",
        "    input_file=covid_predict_manual_valid_inputs_path,\n",
        "    output_file=covid_predict_manual_valid_outputs_path,\n",
        "    # Select the most probable output token at each step.\n",
        "    temperature=0,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-JkhBzACBqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.io.gfile.GFile((covid_predict_manual_valid_outputs_path + \"-1025700\")) as answers, tf.io.gfile.GFile((covid_predict_manual_valid_inputs_path )) as questions:\n",
        "  list_answers = answers.readlines()\n",
        "  list_questions = questions.readlines()\n",
        "  final_manual_valid_df = pd.DataFrame(data={\"questions\":list_questions , \"answers\": list_answers} )\n",
        "  # print(len(), len(questions.readlines()))\n",
        "\n",
        "    \n",
        "    #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qcee7fqCXd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T5_MANUAL_QA_PATH = os.path.join(DATA_DIR, \"T5_MANUAL_QA.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZn14HY8CLJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_manual_valid_df.to_csv(T5_MANUAL_QA_PATH)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoRpEc1EiZLx",
        "colab_type": "text"
      },
      "source": [
        "# More Annotate and Predict, and Compute Exact Matches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDhrwwKXiX1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "more_annotated_path = os.path.join(DATA_DIR, \"df_0.75_qa_dlr_positive_labels.csv\") \n",
        "more_annotated_df = pd.read_csv(more_annotated_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36NlgLdgipEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "more_annotated_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr6k-96UjGZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_more_annotated_df = more_annotated_df[more_annotated_df[\"Validity\"]==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz6RAUW6ifnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# we need a summary statistics, like length, n-gram counts etc.\n",
        "covid_predict_dlr_manual_valid_inputs_path = os.path.join(MODEL_DIR, \"df_075_qa_dlr_positive_labels_inputs.txt\")\n",
        "covid_predict_dlr_manual_valid_outputs_path = os.path.join(MODEL_DIR, \"df_075_qa_dlr_positive_labels_outputs.txt\")\n",
        "with tf.io.gfile.GFile(covid_predict_dlr_manual_valid_inputs_path, \"w\") as f:\n",
        "  for idx, row in valid_more_annotated_df.iterrows():\n",
        "    q = row[\"question\"]\n",
        "    f.write(\"trivia question: %s\\n\" % q.lower()) #TODO: can also invoke the preprocess from earlier\n",
        "\n",
        "model.batch_size = 512  # Min size for small model on v2-8 with parallelism 1.\n",
        "model.predict(\n",
        "    input_file=covid_predict_dlr_manual_valid_inputs_path,\n",
        "    output_file=covid_predict_dlr_manual_valid_outputs_path,\n",
        "    # Select the most probable output token at each step.\n",
        "    temperature=0,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmpDu12zjWdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.io.gfile.GFile((covid_predict_dlr_manual_valid_outputs_path + \"-1025700\")) as answers, tf.io.gfile.GFile((covid_predict_dlr_manual_valid_inputs_path )) as questions:\n",
        "  list_answers = answers.readlines()\n",
        "  list_questions = questions.readlines()\n",
        "  dlr_manual_df = pd.DataFrame(data={\"questions\":list_questions , \"answers\": list_answers} )\n",
        "  # print(len(), len(questions.readlines()))\n",
        "\n",
        "    \n",
        "    #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnLB5tJEkfwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dlr_manual_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEeT4-QHmkAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_more_annotated_df[\"t5_answers\"] = list_answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jiNvE-tlJyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_more_annotated_df.to_csv(os.path.join(BASE_DIR,\"results\",\"QA_SILVER_DUAL_ANSWERS.CSV\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2FLrSmsyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_more_annotated_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-7e0sV0yjqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lengths = [len(seq.split()) for seq in list_answers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_7yjW15y21g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lengths\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG9RLp8n2_UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dWSEBAd3Pwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xTH1H8vBPCI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OziDCohfBOs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized = ' '.join(list_answers).lower().split()\n",
        "fdist = nltk.FreqDist(tokenized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ePsu7fly8VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_tokens = fdist.most_common(15)\n",
        "D = dict(top_tokens)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs4ccnBczOCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ax.bar(\n",
        "fig, ax = plt.subplots()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(11,8)\n",
        "\n",
        "ax.bar(range(len(D)), list(D.values()), align='center', color='b')\n",
        "ax.set_xticks(range(len(D)), )\n",
        "ax.set_xticklabels(list(D.keys()),rotation=45)\n",
        "# deprecated in favour of xticks \n",
        "ax.set_title(\"Most frequent words in T5 answers\")\n",
        "plt.savefig(\"T5 answers\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOmQ0eTRANfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t9ro_iSIyQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# import io\n",
        "# buf = io.BytesIO()\n",
        "# plt.savefig(buf, format='png')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzS45QC3Je7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# buf.seek(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew7CXB70JgQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXoD5HWQ1EEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tokenized = ' '.join(valid_more_annotated_df[\"answer\"].tolist()).lower().split()\n",
        "\n",
        "fdist = nltk.FreqDist(tokenized)\n",
        "top_tokens = fdist.most_common(15)\n",
        "D = dict(top_tokens)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF5HuXOm39E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ax.bar(\n",
        "fig, ax = plt.subplots()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(11,8)\n",
        "ax.bar(range(len(D)), list(D.values()), align='center', color=\"orange\")\n",
        "ax.set_xticks(range(len(D)), )\n",
        "ax.set_xticklabels(list(D.keys()),rotation=45)\n",
        "ax.set_title(\"Most frequent words in rule-based answers\")\n",
        "plt.savefig(\"Rule based answers\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CswtIwc59_5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# top_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-k8FYLS9sJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.savefig(\"Rule based answers\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2bizIPP9mcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.setp(xtickNames, rotation=45, fontsize=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmCk04X94ByR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZHk9nLYNb8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fdist.values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lird0ErxNcVN",
        "colab_type": "text"
      },
      "source": [
        "## Length-Frequency distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8_CLlmsNhqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_lengths = [len(seq.split()) for seq in list_answers]\n",
        "rule_based_lengths = [len(valid_ans.split()) for valid_ans in valid_more_annotated_df[\"answer\"].tolist()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPZmpZJFfZox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transformer_lengths\n",
        "# transformer_lengths =  nltk.FreqDist(' '.join(valid_more_annotated_df[\"t5_answers\"].tolist()).lower().split())\n",
        "# rule_based_lengths = nltk.FreqDist(' '.join(valid_more_annotated_df[\"answer\"].tolist()).lower().split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UcDNdUcgtPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dict(transformer_lengths.most_common()).values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juEB5Zpbg4hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rule_based_lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E_K4M52Owc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.hist(transformer_lengths, label=\"T5 answer lengths\")\n",
        "ax.hist(rule_based_lengths, label=\"Rule based answer lengths\")\n",
        "ax.set_title(\"Distribution of answer lengths\")\n",
        "ax.set_xlabel(\"Number of tokens in sentence\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.set_xlim(0,60)\n",
        "\n",
        "ax.legend()\n",
        "plt.savefig(\"LengthDistributionComparison\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a46_jxhwhDo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(dict(rule_based_lengths.most_common()).values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "albqbTZNOne3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rule_based_lengths = [len(valid_ans.split()) for valid_ans in valid_more_annotated_df[\"answer\"].tolist()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i18G9MARnAOD",
        "colab_type": "text"
      },
      "source": [
        "## Compute some summary statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YAmXvf0m_UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(valid_more_annotated_df[\"answer\"] == valid_more_annotated_df[\"t5_answers\"]).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3xppivuqgNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t00okFWMnVfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def get_exact_match_score(prediction, ground_truth):\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "def get_fuzzy_ratio(prediction, ground_truth):\n",
        "    return fuzz.ratio(normalize_answer(prediction), normalize_answer(ground_truth))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "exact_match_score = 0\n",
        "total = len(valid_more_annotated_df.index)\n",
        "fuzzy_match_score = 0\n",
        "for index, row in valid_more_annotated_df.iterrows():\n",
        "    answer = normalize_answer(str(row['answer']))\n",
        "    predicted_answer = normalize_answer(str(row['t5_answers']))\n",
        "    \n",
        "    exact_match_score += get_exact_match_score(predicted_answer, answer)\n",
        "    fuzzy_match_score += get_fuzzy_ratio(predicted_answer, answer)\n",
        "\n",
        "exact_match_score = 100.0 * exact_match_score / total\n",
        "fuzzy_match_score  /= total\n",
        "\n",
        "print('Exact Match Score: ' + str(exact_match_score))\n",
        "print('Fuzzy Match Score: ' + str(fuzzy_match_score))\n",
        "\n",
        "# predicted_answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXGBMwXOo4Vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtKRIhOPrNN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJpwMi3SrX23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = valid_more_annotated_df[\"answer\"].tolist() +  valid_more_annotated_df[\"t5_answers\"].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyKdoY9brchA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocess corpus\n",
        "preprocessed_corpus = [normalize_answer(elt) for elt in corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNU178ZQrQ8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = vectorizer.fit_transform(preprocessed_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8m2ZigBr0M1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ypy1Mnxr1wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t5_answers_bow = vectorizer.transform(valid_more_annotated_df[\"t5_answers\"].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chQgPUcptCMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_answers_bow = vectorizer.transform(valid_more_annotated_df[\"answer\"].tolist())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a26bZ_NJtXW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pwasExgtSPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsYZXoNZtHa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cosine_sims = cosine_similarity(t5_answers_bow,reg_answers_bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgSRjuW-tlC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cosine_sims.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oF776Wnt48C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cosine_sims.sum()/(1/2*cosine_sims.shape[0]**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6wHRAT_oDdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fuzzywuzzy import fuzz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGD0SeGVo_pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgYyOeQhjvUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use a join, on the question = questions\n",
        "# or simply, append the column at the end!\n",
        "pd.concat([valid_more_annotated_df,dlr_manual_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouUbL62Sjp7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge answers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vbqiq2Ab4PJk"
      },
      "source": [
        "## Predict\n",
        "\n",
        "Now that we have fine-tuned the model, we can feed T5 arbitrary questions and have it predict the answers!\n",
        "\n",
        "There is a significant amount of overhead in initializing the model so this may take a few minutes to run each time even though the prediction itself is quite fast.\n",
        "\n",
        "\n",
        "To avoid this overhead, you might consider exporting a `SavedModel` and running it on [Cloud ML Engine](https://cloud.google.com/ml-engine/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "xatHPuCJsPns",
        "colab": {}
      },
      "source": [
        "question_1 = \"What is known about COVID-19 therapeutics?\" #@param {type:\"string\"}\n",
        "question_2 = \"What is the most populous country in the world?\" #@param {type:\"string\"}\n",
        "question_3 = \"Who are the 4 members of The Beatles?\" #@param {type:\"string\"}\n",
        "question_4 = \"How many teeth do humans have?\" #@param {type:\"string\"}\n",
        "\n",
        "questions = [question_1, question_2, question_3, question_4]\n",
        "\n",
        "now = time.time()\n",
        "# Write out the supplied questions to text files.\n",
        "predict_inputs_path = os.path.join(MODEL_DIR, \"predict_inputs_%d.txt\" % now)\n",
        "predict_outputs_path = os.path.join(MODEL_DIR, \"predict_outputs_%d.txt\" % now)\n",
        "# Manually apply preprocessing by prepending \"triviaqa question:\".\n",
        "with tf.io.gfile.GFile(predict_inputs_path, \"w\") as f:\n",
        "  for q in questions:\n",
        "    f.write(\"trivia question: %s\\n\" % q.lower())\n",
        "\n",
        "# Ignore any logging so that we only see the model's answers to the questions.\n",
        "# with tf_verbosity_level('ERROR'):\n",
        "model.batch_size = 8  # Min size for small model on v2-8 with parallelism 1.\n",
        "model.predict(\n",
        "    input_file=predict_inputs_path,\n",
        "    output_file=predict_outputs_path,\n",
        "    # Select the most probable output token at each step.\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# The output filename will have the checkpoint appended so we glob to get \n",
        "# the latest.\n",
        "prediction_files = sorted(tf.io.gfile.glob(predict_outputs_path + \"*\"))\n",
        "print(\"\\nPredictions using checkpoint %s:\\n\" % prediction_files[-1].split(\"-\")[-1])\n",
        "with tf.io.gfile.GFile(prediction_files[-1]) as f:\n",
        "  for q, a in zip(questions, f):\n",
        "    if q:\n",
        "      print(\"Q: \" + q)\n",
        "      print(\"A: \" + a)\n",
        "      print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xxElhphBZMD5"
      },
      "source": [
        "# Export Model for Serving\n",
        "\n",
        "As mentioned in the previous section, exporting a [`SavedModel`](https://www.tensorflow.org/guide/saved_model) can be useful for improving performance during inference or allowing your model to be deployed on a variety of platforms (e.g., TFLite, TensorFlow.js, TensorFlow Serving, or TensorFlow Hub).\n",
        "\n",
        "**Note:** we currently only support exporting a SavedModel that runs on both CPU and GPU, not TPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l_YuEL9FZ-UR"
      },
      "source": [
        "## Export SavedModel\n",
        "\n",
        "We first export the SavedModel. We set a batch size of 1 for simplicity, but it may be more efficient to use a larger batch size if you want to handle multiple requests per call.\n",
        "\n",
        "For 3B and 11B models the export will take approximately 30-45 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eWu8lbh3aHjc",
        "colab": {}
      },
      "source": [
        "export_dir = os.path.join(MODEL_DIR, \"export\")\n",
        "\n",
        "model.batch_size = 1 # make one prediction per call\n",
        "saved_model_path = model.export(\n",
        "    export_dir,\n",
        "    checkpoint_step=-1,  # use most recent\n",
        "    beam_size=1,  # no beam search\n",
        "    temperature=1.0,  # sample according to predicted distribution\n",
        ")\n",
        "print(\"Model saved to:\", saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PZ8WXpFkaNTP"
      },
      "source": [
        "## Load SavedModel\n",
        "\n",
        "One way to test our model is to load it either in eager mode or a TF 1.x session so that we can repeatedly predict from the model without the overhead of loading the graph and weights each time.\n",
        "\n",
        "We pay the overhead once here, but it shouldn't take more than a few minutes.\n",
        "\n",
        "\n",
        "### Optional: Switch to GPU Runtime\n",
        "\n",
        "Changing the runtime type to GPU in the `Runtime` menu above before loading the SavedModel will speed up inference by using the GPU instead of CPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "LyBuc4WH-cyB",
        "colab": {}
      },
      "source": [
        "#@title Optional: Run this cell to re-initialize if you switched to GPU runtime.\n",
        "%tensorflow_version 2.x\n",
        "!pip install tensorflow-text\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1TpeMFGhaN7r",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text  # Required to run exported model.\n",
        "\n",
        "def load_predict_fn(model_path):\n",
        "  if tf.executing_eagerly():\n",
        "    print(\"Loading SavedModel in eager mode.\")\n",
        "    imported = tf.saved_model.load(model_path, [\"serve\"])\n",
        "    return lambda x: imported.signatures['serving_default'](tf.constant(x))['outputs'].numpy()\n",
        "  else:\n",
        "    print(\"Loading SavedModel in tf 1.x graph mode.\")\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    sess = tf.compat.v1.Session()\n",
        "    meta_graph_def = tf.compat.v1.saved_model.load(sess, [\"serve\"], model_path)\n",
        "    signature_def = meta_graph_def.signature_def[\"serving_default\"]\n",
        "    return lambda x: sess.run(\n",
        "        fetches=signature_def.outputs[\"outputs\"].name, \n",
        "        feed_dict={signature_def.inputs[\"input\"].name: x}\n",
        "    )\n",
        "\n",
        "predict_fn = load_predict_fn(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YbGC8xefaYtV"
      },
      "source": [
        "## Predict\n",
        "\n",
        "We can now call the predict method with different inputs each time and relatively quickly get results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3WA0BYI9abgv",
        "colab": {}
      },
      "source": [
        "def answer(question):\n",
        "  return predict_fn([question])[0].decode('utf-8')\n",
        "\n",
        "for question in [\"trivia question: where is the google headquarters?\",\n",
        "                 \"trivia question: what is the most populous country in the world?\",\n",
        "                 \"trivia question: who are the 4 members of the beatles?\",\n",
        "                 \"trivia question: how many teeth do humans have?\"]:\n",
        "    print(answer(question))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ePXPEQhDafmV"
      },
      "source": [
        "## Deploy SavedModel\n",
        "\n",
        "You can now deploy your SavedModel for serving (e.g., with [TensorFlow Serving](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1N3fEtEpLuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}